{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Retrieval-Augmented Generation (RAG) Agent Development\n"
      ],
      "metadata": {
        "id": "qHI8yj74cT72"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup and Imports"
      ],
      "metadata": {
        "id": "iTFH0xfLhKQx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2 python-docx streamlit torch sentence-transformers scikit-learn plotly unittest2 llama-index llama-index-embeddings-huggingface llama-index-llms-fireworks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6XfgVdJ8iPso",
        "outputId": "1329efb4-9f8a-44ba-a403-bb8e186d6e2f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.10/dist-packages (1.1.2)\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.10/dist-packages (1.37.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (5.15.0)\n",
            "Requirement already satisfied: unittest2 in /usr/local/lib/python3.10/dist-packages (1.1.0)\n",
            "Requirement already satisfied: llama-index in /usr/local/lib/python3.10/dist-packages (0.10.58)\n",
            "Requirement already satisfied: llama-index-embeddings-huggingface in /usr/local/lib/python3.10/dist-packages (0.2.2)\n",
            "Collecting llama-index-llms-fireworks\n",
            "  Downloading llama_index_llms_fireworks-0.1.7-py3-none-any.whl.metadata (669 bytes)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.4)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.12.2)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.4.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<3,>=1.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.1)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.1.4)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (17.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.1)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.43)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Requirement already satisfied: watchdog<5,>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.5.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.82)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.42.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.23.5)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Collecting argparse (from unittest2)\n",
            "  Using cached argparse-1.4.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
            "Requirement already satisfied: six>=1.4 in /usr/local/lib/python3.10/dist-packages (from unittest2) (1.16.0)\n",
            "Requirement already satisfied: traceback2 in /usr/local/lib/python3.10/dist-packages (from unittest2) (1.4.0)\n",
            "Requirement already satisfied: llama-index-agent-openai<0.3.0,>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.2.9)\n",
            "Requirement already satisfied: llama-index-cli<0.2.0,>=0.1.2 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.1.13)\n",
            "Requirement already satisfied: llama-index-core==0.10.58 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.10.58)\n",
            "Requirement already satisfied: llama-index-embeddings-openai<0.2.0,>=0.1.5 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.1.11)\n",
            "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.2.7)\n",
            "Requirement already satisfied: llama-index-legacy<0.10.0,>=0.9.48 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.9.48)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.2.0,>=0.1.27 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.1.27)\n",
            "Requirement already satisfied: llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.1.8)\n",
            "Requirement already satisfied: llama-index-program-openai<0.2.0,>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.1.7)\n",
            "Requirement already satisfied: llama-index-question-gen-openai<0.2.0,>=0.1.2 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.1.3)\n",
            "Requirement already satisfied: llama-index-readers-file<0.2.0,>=0.1.4 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.1.32)\n",
            "Requirement already satisfied: llama-index-readers-llama-parse>=0.1.2 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.1.6)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.58->llama-index) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.10.58->llama-index) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.58->llama-index) (3.9.5)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.58->llama-index) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.58->llama-index) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.58->llama-index) (1.0.8)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.58->llama-index) (0.27.0)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.58->llama-index) (1.6.0)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.58->llama-index) (3.8.1)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.58->llama-index) (1.37.1)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.58->llama-index) (0.7.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.58->llama-index) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from llama-index-core==0.10.58->llama-index) (1.16.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
            "Requirement already satisfied: minijinja>=1.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.0.1)\n",
            "Requirement already satisfied: llama-cloud>=0.0.11 in /usr/local/lib/python3.10/dist-packages (from llama-index-indices-managed-llama-cloud>=0.2.0->llama-index) (0.0.11)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.12.3)\n",
            "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (4.3.1)\n",
            "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (0.0.26)\n",
            "Requirement already satisfied: llama-parse>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-readers-llama-parse>=0.1.2->llama-index) (0.4.9)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.7.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2024.5.15)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: linecache2 in /usr/local/lib/python3.10/dist-packages (from traceback2->unittest2) (1.0.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.58->llama-index) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.58->llama-index) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.58->llama-index) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.58->llama-index) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.58->llama-index) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core==0.10.58->llama-index) (4.0.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index) (2.5)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.19.1)\n",
            "Requirement already satisfied: pydantic>=1.10 in /usr/local/lib/python3.10/dist-packages (from llama-cloud>=0.0.11->llama-index-indices-managed-llama-cloud>=0.2.0->llama-index) (2.8.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.10.58->llama-index) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.10.58->llama-index) (1.0.5)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core==0.10.58->llama-index) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core==0.10.58->llama-index) (0.14.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index-core==0.10.58->llama-index) (1.7.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core==0.10.58->llama-index) (3.0.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index-core==0.10.58->llama-index) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index-core==0.10.58->llama-index) (3.21.3)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core==0.10.58->llama-index) (1.2.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llama-cloud>=0.0.11->llama-index-indices-managed-llama-cloud>=0.2.0->llama-index) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.10->llama-cloud>=0.0.11->llama-index-indices-managed-llama-cloud>=0.2.0->llama-index) (2.20.1)\n",
            "Downloading llama_index_llms_fireworks-0.1.7-py3-none-any.whl (4.5 kB)\n",
            "Using cached argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Installing collected packages: argparse, llama-index-llms-fireworks\n",
            "Successfully installed argparse-1.4.0 llama-index-llms-fireworks-0.1.7\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse"
                ]
              },
              "id": "825503ef2c654d9f9a8cebd4e3011419"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import csv\n",
        "import io\n",
        "from typing import List\n",
        "\n",
        "import PyPDF2\n",
        "import docx\n",
        "import streamlit as st\n",
        "import torch\n",
        "from llama_index.core import VectorStoreIndex, Document, Settings\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.llms.fireworks import Fireworks\n",
        "from llama_index.core.retrievers import KeywordTableSimpleRetriever\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.cluster import HDBSCAN\n",
        "import plotly.graph_objects as go\n",
        "import unittest\n",
        "from unittest.mock import Mock, patch\n",
        "import nest_asyncio"
      ],
      "metadata": {
        "collapsed": true,
        "id": "1OLhbPzX6kEf"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### API Key Input"
      ],
      "metadata": {
        "id": "lJqShXiyh_Ge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "\n",
        "fireworks_api_key = getpass.getpass(\"Enter your Fireworks API key: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOFkeXKjiAgH",
        "outputId": "6c8a5753-d3a9-4aa9-c880-d029cb85d80a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Fireworks API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nest_asyncio.apply()\n",
        "\n",
        "print(\"All necessary modules imported successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D33AytRJu9GB",
        "outputId": "877d3579-2b1d-404f-ff6f-cb87fac06a0c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All necessary modules imported successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Document Preprocessing\n"
      ],
      "metadata": {
        "id": "uI5Lid68dM3m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RAGSystem1:\n",
        "    def __init__(self, fireworks_api_key, device=\"cuda\"):\n",
        "        self.device = device if torch.cuda.is_available() else \"cpu\"\n",
        "        print(f\"Using device: {self.device}\")\n",
        "\n",
        "        self.llm = Fireworks(\n",
        "            api_key=fireworks_api_key,\n",
        "            model=\"accounts/fireworks/models/firefunction-v1\"\n",
        "        )\n",
        "\n",
        "        self.embed_model = HuggingFaceEmbedding(\n",
        "            model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "            device=self.device\n",
        "        )\n",
        "\n",
        "        self.sentence_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "        Settings.llm = self.llm\n",
        "        Settings.embed_model = self.embed_model\n",
        "\n",
        "        self.document_cache = {}\n",
        "        print(\"RAGSystem initialized.\")\n",
        "\n",
        "    @staticmethod\n",
        "    def _extract_text_from_file(uploaded_file):\n",
        "        file_extension = uploaded_file.name.split('.')[-1].lower()\n",
        "\n",
        "        if file_extension == 'pdf':\n",
        "            pdf_reader = PyPDF2.PdfReader(io.BytesIO(uploaded_file.read()))\n",
        "            return ' '.join(page.extract_text() for page in pdf_reader.pages)\n",
        "\n",
        "        elif file_extension == 'docx':\n",
        "            doc = docx.Document(io.BytesIO(uploaded_file.read()))\n",
        "            return ' '.join(paragraph.text for paragraph in doc.paragraphs)\n",
        "\n",
        "        elif file_extension == 'csv':\n",
        "            csv_content = uploaded_file.read().decode('utf-8')\n",
        "            csv_reader = csv.reader(io.StringIO(csv_content))\n",
        "            return ' '.join(' '.join(row) for row in csv_reader)\n",
        "\n",
        "        elif file_extension == 'txt':\n",
        "            return uploaded_file.read().decode('utf-8')\n",
        "\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported file type: {file_extension}\")\n",
        "\n",
        "    def extract_text_from_file(self, uploaded_file):\n",
        "        return self._extract_text_from_file(uploaded_file)\n",
        "\n",
        "    async def generate_meaningful_chunks(self, text, chunk_size=512, chunk_overlap=50, min_cluster_size=5):\n",
        "        sentences = text.split('.')\n",
        "        sentence_embeddings = await asyncio.to_thread(\n",
        "            self.sentence_model.encode, sentences, batch_size=64\n",
        "        )\n",
        "\n",
        "        clusterer = HDBSCAN(min_cluster_size=min_cluster_size, metric='euclidean')\n",
        "        clusterer.fit(sentence_embeddings)\n",
        "        labels = clusterer.labels_\n",
        "\n",
        "        chunks = []\n",
        "        for label in set(labels):\n",
        "            cluster_sentences = [sentences[i] for i in range(len(sentences)) if labels[i] == label]\n",
        "            if len(cluster_sentences) >= min_cluster_size:\n",
        "                chunks.append(' '.join(cluster_sentences))\n",
        "\n",
        "        return chunks\n",
        "\n",
        "    async def process_file(self, uploaded_file, chunk_size, chunk_overlap, min_cluster_size):\n",
        "        if uploaded_file.name in self.document_cache:\n",
        "            return self.document_cache[uploaded_file.name]\n",
        "\n",
        "        try:\n",
        "            text = self.extract_text_from_file(uploaded_file)\n",
        "            chunks = await self.generate_meaningful_chunks(text, chunk_size, chunk_overlap, min_cluster_size)\n",
        "            documents = [Document(text=chunk) for chunk in chunks]\n",
        "            self.document_cache[uploaded_file.name] = documents\n",
        "            return documents\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {uploaded_file.name}: {str(e)}\")\n",
        "            return []\n",
        "\n",
        "# Demonstrate document preprocessing\n",
        "rag_system = RAGSystem1(fireworks_api_key)\n",
        "mock_file = Mock()\n",
        "mock_file.name = 'test.txt'\n",
        "mock_file.read.return_value = b'This is a test document about RAG systems. It contains multiple sentences. Each sentence should be processed.'\n",
        "\n",
        "async def test_preprocessing():\n",
        "    documents = await rag_system.process_file(mock_file, 512, 50, 2)\n",
        "    print(f\"Number of chunks generated: {len(documents)}\")\n",
        "    print(f\"First chunk: {documents[0].text[:100]}...\")\n",
        "\n",
        "await test_preprocessing()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2ZQIay2dS-g",
        "outputId": "d1ff551d-6eae-47cc-cf8f-8472a339fb06"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "RAGSystem initialized.\n",
            "Number of chunks generated: 1\n",
            "First chunk: This is a test document about RAG systems  It contains multiple sentences  Each sentence should be p...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Retrieval System Development\n"
      ],
      "metadata": {
        "id": "6WGDL3spdYdO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RAGSystem2(RAGSystem):  # Continuing the class definition\n",
        "  async def create_index(self, documents):\n",
        "      try:\n",
        "          index = await asyncio.to_thread(VectorStoreIndex.from_documents, documents)\n",
        "          return index\n",
        "      except Exception as e:\n",
        "          print(f\"Error creating index: {str(e)}\")\n",
        "          return None\n",
        "\n",
        "  def process_query(self, query, index):\n",
        "      if not index:\n",
        "          print(\"Index not available for query processing.\")\n",
        "          return None\n",
        "\n",
        "      try:\n",
        "          vector_retriever = index.as_retriever(similarity_top_k=5)\n",
        "          vector_nodes = vector_retriever.retrieve(query)\n",
        "\n",
        "          keyword_nodes = []\n",
        "          for node in vector_nodes:\n",
        "              doc_text = node.node.text\n",
        "              if any(keyword in doc_text.lower() for keyword in query.lower().split()):\n",
        "                  keyword_nodes.append(node)\n",
        "\n",
        "          combined_nodes = list({node.node.node_id: node for node in vector_nodes + keyword_nodes}.values())\n",
        "          print(f\"Combined results before sorting: {len(combined_nodes)} nodes\")\n",
        "\n",
        "          combined_nodes.sort(\n",
        "              key=lambda x: x.score + (1 if any(keyword in x.node.text.lower() for keyword in query.lower().split()) else 0),\n",
        "              reverse=True\n",
        "          )\n",
        "\n",
        "          top_nodes = combined_nodes[:5]\n",
        "          print(f\"Top nodes: {top_nodes}\")\n",
        "\n",
        "          query_engine = index.as_query_engine()\n",
        "          response = query_engine.query(query)\n",
        "\n",
        "          return response\n",
        "\n",
        "      except Exception as e:\n",
        "          print(f\"Error processing query: {str(e)}\")\n",
        "          return None\n",
        "\n",
        "# Demonstrate retrieval system\n",
        "async def test_retrieval():\n",
        "    rag_system = RAGSystem2(fireworks_api_key)\n",
        "    documents = await rag_system.process_file(mock_file, 512, 50, 2)\n",
        "    index = await rag_system.create_index(documents)\n",
        "    if index:\n",
        "        print(\"Index created successfully.\")\n",
        "        response = rag_system.process_query(\"What is this document about?\", index)\n",
        "        if response:\n",
        "            print(f\"Query response: {response.response}\")\n",
        "    else:\n",
        "        print(\"Failed to create index.\")\n",
        "\n",
        "await test_retrieval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHzg_tQPdZxq",
        "outputId": "74ee01ed-24cc-4138-feaa-fda235f01e8d"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "RAGSystem initialized.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tiktoken/core.py:50: RuntimeWarning: coroutine 'test_preprocessing' was never awaited\n",
            "  self._core_bpe = _tiktoken.CoreBPE(mergeable_ranks, special_tokens, pat_str)\n",
            "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
            "/usr/local/lib/python3.10/dist-packages/tiktoken/core.py:50: RuntimeWarning: coroutine 'RAGSystem.process_file' was never awaited\n",
            "  self._core_bpe = _tiktoken.CoreBPE(mergeable_ranks, special_tokens, pat_str)\n",
            "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index created successfully.\n",
            "Combined results before sorting: 1 nodes\n",
            "Top nodes: [NodeWithScore(node=TextNode(id_='7e2a2de6-987a-4b95-8e87-95325780baf4', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='c78b01c3-17d3-4506-9644-c867e9d520a4', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='0970eba4f9de5d3ac7c0e2a44096d897ea2640b887f3f5e708036a04ce62153f')}, text='This is a test document about RAG systems  It contains multiple sentences  Each sentence should be processed', mimetype='text/plain', start_char_idx=0, end_char_idx=108, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.39294020255501316)]\n",
            "Query response: This document is about RAG systems.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Generation Model Integration\n"
      ],
      "metadata": {
        "id": "ENFZSwmHdeIp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RAGSystem3(RAGSystem):  # Continuing the class definition\n",
        "    async def run_rag(self, query, uploaded_files, chunk_size, chunk_overlap, min_cluster_size):\n",
        "        documents = []\n",
        "        total_files = len(uploaded_files)\n",
        "        print(\"Processing uploaded files...\")\n",
        "        tasks = [self.process_file(file, chunk_size, chunk_overlap, min_cluster_size) for file in uploaded_files]\n",
        "        documents = []\n",
        "\n",
        "        for i, uploaded_file in enumerate(uploaded_files, start=1):\n",
        "            print(f\"Processing file {i}/{total_files}: {uploaded_file.name}\")\n",
        "            file_documents = await self.process_file(uploaded_file, chunk_size, chunk_overlap, min_cluster_size)\n",
        "            if file_documents:\n",
        "                documents.extend(file_documents)\n",
        "\n",
        "        if documents:\n",
        "            print(\"Creating index from documents...\")\n",
        "            index = await self.create_index(documents)\n",
        "            if index:\n",
        "                response = self.process_query(query, index)\n",
        "                return response\n",
        "            else:\n",
        "                print(\"No valid documents were processed. Please check your file formats and content.\")\n",
        "                return None\n",
        "        else:\n",
        "            print(\"No documents were processed.\")\n",
        "            return None\n",
        "\n",
        "    def display_results(self, response):\n",
        "        if not response:\n",
        "            return\n",
        "\n",
        "        print(\"Generated Response:\", response.response)\n",
        "\n",
        "        print(\"Source Documents:\")\n",
        "        for node in response.source_nodes:\n",
        "            print(f\"- {node.node.get_content()[:100]}...\")\n",
        "\n",
        "        scores = [node.score for node in response.source_nodes]\n",
        "        fig = go.Figure(data=[go.Bar(y=scores)])\n",
        "        fig.update_layout(title=\"Relevance Scores of Retrieved Documents\",\n",
        "                          xaxis_title=\"Document\",\n",
        "                          yaxis_title=\"Relevance Score\")\n",
        "        fig.show()\n",
        "\n",
        "# Demonstrate full RAG process\n",
        "async def test_full_rag():\n",
        "    rag_system = RAGSystem3(fireworks_api_key)\n",
        "    response = await rag_system.run_rag(\"What is this document about?\", [mock_file], 512, 50, 2)\n",
        "    if response:\n",
        "        rag_system.display_results(response)\n",
        "    else:\n",
        "        print(\"No response generated.\")\n",
        "\n",
        "asyncio.run(test_full_rag())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 788
        },
        "id": "DyQgFEnKdhTp",
        "outputId": "a3e1c633-168a-46f1-c1c1-81b53f793243"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "RAGSystem initialized.\n",
            "Processing uploaded files...\n",
            "Processing file 1/1: test.txt\n",
            "Creating index from documents...\n",
            "Combined results before sorting: 1 nodes\n",
            "Top nodes: [NodeWithScore(node=TextNode(id_='7818c153-ceee-414b-93d6-f05f17fd2523', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='9539d047-e005-4385-899b-9cf39c0fd9a4', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='0970eba4f9de5d3ac7c0e2a44096d897ea2640b887f3f5e708036a04ce62153f')}, text='This is a test document about RAG systems  It contains multiple sentences  Each sentence should be processed', mimetype='text/plain', start_char_idx=0, end_char_idx=108, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.39294020255501316)]\n",
            "Generated Response: This document is about RAG systems.\n",
            "Source Documents:\n",
            "- This is a test document about RAG systems  It contains multiple sentences  Each sentence should be p...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/plotly/graph_objs/_bar.py:658: RuntimeWarning: coroutine 'RAGSystem.process_file' was never awaited\n",
            "  def hovertextsrc(self, val):\n",
            "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"bb2c7283-3a4c-48e7-aa6b-379cae839566\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"bb2c7283-3a4c-48e7-aa6b-379cae839566\")) {                    Plotly.newPlot(                        \"bb2c7283-3a4c-48e7-aa6b-379cae839566\",                        [{\"y\":[0.39294020255501316],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"candlestick\":[{\"decreasing\":{\"line\":{\"color\":\"#000033\"}},\"increasing\":{\"line\":{\"color\":\"#000032\"}},\"type\":\"candlestick\"}],\"contourcarpet\":[{\"colorscale\":[[0.0,\"#000011\"],[0.1111111111111111,\"#000012\"],[0.2222222222222222,\"#000013\"],[0.3333333333333333,\"#000014\"],[0.4444444444444444,\"#000015\"],[0.5555555555555556,\"#000016\"],[0.6666666666666666,\"#000017\"],[0.7777777777777778,\"#000018\"],[0.8888888888888888,\"#000019\"],[1.0,\"#000020\"]],\"type\":\"contourcarpet\"}],\"contour\":[{\"colorscale\":[[0.0,\"#000011\"],[0.1111111111111111,\"#000012\"],[0.2222222222222222,\"#000013\"],[0.3333333333333333,\"#000014\"],[0.4444444444444444,\"#000015\"],[0.5555555555555556,\"#000016\"],[0.6666666666666666,\"#000017\"],[0.7777777777777778,\"#000018\"],[0.8888888888888888,\"#000019\"],[1.0,\"#000020\"]],\"type\":\"contour\"}],\"heatmap\":[{\"colorscale\":[[0.0,\"#000011\"],[0.1111111111111111,\"#000012\"],[0.2222222222222222,\"#000013\"],[0.3333333333333333,\"#000014\"],[0.4444444444444444,\"#000015\"],[0.5555555555555556,\"#000016\"],[0.6666666666666666,\"#000017\"],[0.7777777777777778,\"#000018\"],[0.8888888888888888,\"#000019\"],[1.0,\"#000020\"]],\"type\":\"heatmap\"}],\"histogram2d\":[{\"colorscale\":[[0.0,\"#000011\"],[0.1111111111111111,\"#000012\"],[0.2222222222222222,\"#000013\"],[0.3333333333333333,\"#000014\"],[0.4444444444444444,\"#000015\"],[0.5555555555555556,\"#000016\"],[0.6666666666666666,\"#000017\"],[0.7777777777777778,\"#000018\"],[0.8888888888888888,\"#000019\"],[1.0,\"#000020\"]],\"type\":\"histogram2d\"}],\"icicle\":[{\"textfont\":{\"color\":\"white\"},\"type\":\"icicle\"}],\"sankey\":[{\"textfont\":{\"color\":\"#000036\"},\"type\":\"sankey\"}],\"scatter\":[{\"marker\":{\"line\":{\"width\":0}},\"type\":\"scatter\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#000038\"},\"font\":{\"color\":\"#000037\"},\"line\":{\"color\":\"#000039\"}},\"header\":{\"fill\":{\"color\":\"#000040\"},\"font\":{\"color\":\"#000036\"},\"line\":{\"color\":\"#000039\"}},\"type\":\"table\"}],\"waterfall\":[{\"connector\":{\"line\":{\"color\":\"#000036\",\"width\":2}},\"decreasing\":{\"marker\":{\"color\":\"#000033\"}},\"increasing\":{\"marker\":{\"color\":\"#000032\"}},\"totals\":{\"marker\":{\"color\":\"#000034\"}},\"type\":\"waterfall\"}]},\"layout\":{\"coloraxis\":{\"colorscale\":[[0.0,\"#000011\"],[0.1111111111111111,\"#000012\"],[0.2222222222222222,\"#000013\"],[0.3333333333333333,\"#000014\"],[0.4444444444444444,\"#000015\"],[0.5555555555555556,\"#000016\"],[0.6666666666666666,\"#000017\"],[0.7777777777777778,\"#000018\"],[0.8888888888888888,\"#000019\"],[1.0,\"#000020\"]]},\"colorscale\":{\"diverging\":[[0.0,\"#000021\"],[0.1,\"#000022\"],[0.2,\"#000023\"],[0.3,\"#000024\"],[0.4,\"#000025\"],[0.5,\"#000026\"],[0.6,\"#000027\"],[0.7,\"#000028\"],[0.8,\"#000029\"],[0.9,\"#000030\"],[1.0,\"#000031\"]],\"sequential\":[[0.0,\"#000011\"],[0.1111111111111111,\"#000012\"],[0.2222222222222222,\"#000013\"],[0.3333333333333333,\"#000014\"],[0.4444444444444444,\"#000015\"],[0.5555555555555556,\"#000016\"],[0.6666666666666666,\"#000017\"],[0.7777777777777778,\"#000018\"],[0.8888888888888888,\"#000019\"],[1.0,\"#000020\"]],\"sequentialminus\":[[0.0,\"#000011\"],[0.1111111111111111,\"#000012\"],[0.2222222222222222,\"#000013\"],[0.3333333333333333,\"#000014\"],[0.4444444444444444,\"#000015\"],[0.5555555555555556,\"#000016\"],[0.6666666666666666,\"#000017\"],[0.7777777777777778,\"#000018\"],[0.8888888888888888,\"#000019\"],[1.0,\"#000020\"]]},\"colorway\":[\"#000001\",\"#000002\",\"#000003\",\"#000004\",\"#000005\",\"#000006\",\"#000007\",\"#000008\",\"#000009\",\"#000010\"]}},\"title\":{\"text\":\"Relevance Scores of Retrieved Documents\"},\"xaxis\":{\"title\":{\"text\":\"Document\"}},\"yaxis\":{\"title\":{\"text\":\"Relevance Score\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('bb2c7283-3a4c-48e7-aa6b-379cae839566');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Testing and Evaluation\n"
      ],
      "metadata": {
        "id": "IeoSPln0dt3n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import unittest\n",
        "from unittest.mock import patch, mock_open\n",
        "import asyncio\n",
        "\n",
        "# Mocking the SentenceTransformer for testing purposes\n",
        "class MockSentenceTransformer:\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        pass\n",
        "\n",
        "    def encode(self, texts, **kwargs):\n",
        "        return [\"mock_embedding\" for _ in texts]\n",
        "\n",
        "class HuggingFaceEmbedding:\n",
        "    def __init__(self, model_name):\n",
        "        self._model = MockSentenceTransformer(model_name)\n",
        "\n",
        "    def encode(self, texts):\n",
        "        return self._model.encode(texts)\n",
        "\n",
        "class RAGSystem:\n",
        "    def __init__(self, api_key):\n",
        "        self.api_key = api_key\n",
        "        self.embed_model = HuggingFaceEmbedding(\"dummy_model_name\")\n",
        "\n",
        "    async def run_rag(self, query, uploaded_files, max_length, top_k, num_return_sequences):\n",
        "        # Dummy response for testing purposes\n",
        "        return \"This is a test response.\"\n",
        "\n",
        "class TestRAGSystem(unittest.TestCase):\n",
        "    @patch('builtins.open', new_callable=mock_open, read_data=\"This is a test document.\")\n",
        "    def test_rag_system(self, mock_file):\n",
        "        rag_system = RAGSystem(\"dummy_api_key\")\n",
        "\n",
        "        mock_file.name = 'test.txt'\n",
        "        uploaded_files = [mock_file]\n",
        "        query = \"What is this document about?\"\n",
        "\n",
        "        response = asyncio.run(rag_system.run_rag(query, uploaded_files, 512, 50, 5))\n",
        "\n",
        "        self.assertIsNotNone(response)\n",
        "\n",
        "def evaluate_performance(responses, ground_truth):\n",
        "    correct = sum(r == gt for r, gt in zip(responses, ground_truth))\n",
        "    accuracy = correct / len(responses)\n",
        "    return {\"accuracy\": accuracy}\n",
        "\n",
        "def generate_evaluation_report(test_results, performance_metrics):\n",
        "    report = \"RAG System Evaluation Report\\n\"\n",
        "    report += \"===========================\\n\\n\"\n",
        "\n",
        "    report += \"1. Unit Test Results:\\n\"\n",
        "    for test, result in test_results.items():\n",
        "        report += f\"   - {test}: {'Passed' if result else 'Failed'}\\n\"\n",
        "\n",
        "    report += \"\\n2. Performance Metrics:\\n\"\n",
        "    for metric, value in performance_metrics.items():\n",
        "        report += f\"   - {metric}: {value}\\n\"\n",
        "\n",
        "    report += \"\\n3. Simulated User Feedback:\\n\"\n",
        "    report += \"   [Include user feedback from testing sessions]\\n\"\n",
        "\n",
        "    return report\n",
        "\n",
        "# Run tests and evaluation\n",
        "def run_tests_and_evaluation():\n",
        "    # Run tests\n",
        "    test_suite = unittest.TestLoader().loadTestsFromTestCase(TestRAGSystem)\n",
        "    test_results = unittest.TextTestRunner(verbosity=2).run(test_suite)\n",
        "\n",
        "    # Process test results\n",
        "    test_results_dict = {}\n",
        "    for test, error in test_results.errors + test_results.failures:\n",
        "        test_results_dict[test._testMethodName] = False\n",
        "    for test in test_suite:\n",
        "        test_name = getattr(test, '_testMethodName', None)\n",
        "        if test_name and test_name not in test_results_dict:\n",
        "            test_results_dict[test_name] = True\n",
        "\n",
        "    # Dummy implementation of rag_system for the evaluation\n",
        "    rag_system = RAGSystem(\"dummy_api_key\")\n",
        "    mock_file = mock_open(read_data=\"This is a test document.\").return_value\n",
        "\n",
        "    # Evaluate performance (this is a simplified example)\n",
        "    test_queries = [\"What is RAG?\"]\n",
        "    test_ground_truth = [\"RAG is a system that combines retrieval and generation.\"]\n",
        "    responses = [rag_system.run_rag(query, [mock_file], 512, 50, 2) for query in test_queries]\n",
        "    responses = [r if r else \"\" for r in asyncio.run(asyncio.gather(*responses))]\n",
        "    metrics = evaluate_performance(responses, test_ground_truth)\n",
        "\n",
        "    # Generate and print evaluation report\n",
        "    report = generate_evaluation_report(test_results_dict, metrics)\n",
        "    print(report)\n",
        "\n",
        "run_tests_and_evaluation()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfOj9PosdqKo",
        "outputId": "a560d467-d603-4229-b417-47c1c2703a34"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "test_rag_system (__main__.TestRAGSystem) ... ok\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 1 test in 0.010s\n",
            "\n",
            "OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RAG System Evaluation Report\n",
            "===========================\n",
            "\n",
            "1. Unit Test Results:\n",
            "\n",
            "2. Performance Metrics:\n",
            "   - accuracy: 0.0\n",
            "\n",
            "3. Simulated User Feedback:\n",
            "   [Include user feedback from testing sessions]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Run RAG System\n"
      ],
      "metadata": {
        "id": "6GDFxcWJdjRQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "async def main():\n",
        "    print(\"Running full RAG system demo...\")\n",
        "\n",
        "    # Example usage with multiple mock files\n",
        "    mock_file1 = Mock()\n",
        "    mock_file1.name = 'test1.txt'\n",
        "    mock_file1.read.return_value = b'This is a test document about RAG systems.'\n",
        "\n",
        "    mock_file2 = Mock()\n",
        "    mock_file2.name = 'test2.txt'\n",
        "    mock_file2.read.return_value = b'RAG systems combine retrieval and generation for better results.'\n",
        "\n",
        "    query = \"Explain what RAG systems are and how they work.\"\n",
        "    rag_system = RAGSystem3(fireworks_api_key)\n",
        "    response = await rag_system.run_rag(query, [mock_file1, mock_file2], 512, 50, 2)\n",
        "\n",
        "    if response:\n",
        "        rag_system.display_results(response)\n",
        "    else:\n",
        "        print(\"No response generated.\")\n",
        "\n",
        "asyncio.run(main())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 788
        },
        "id": "8g0J8OGtdzHX",
        "outputId": "48e6c590-a0b9-43cc-a6bf-f18b9e3e8e9c"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running full RAG system demo...\n",
            "Using device: cpu\n",
            "RAGSystem initialized.\n",
            "Processing uploaded files...\n",
            "Processing file 1/2: test1.txt\n",
            "Processing file 2/2: test2.txt\n",
            "Creating index from documents...\n",
            "Combined results before sorting: 2 nodes\n",
            "Top nodes: [NodeWithScore(node=TextNode(id_='019a5006-3285-4730-b366-2a56179ec106', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='03d3a8d4-23c4-4da8-86af-eaed74f99559', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='82cf2869987e3e72bef2ed4eeb49c5920f26913ba6fe58a51bea524140c62144')}, text='This is a test document about RAG systems', mimetype='text/plain', start_char_idx=0, end_char_idx=41, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.8703420561313896), NodeWithScore(node=TextNode(id_='7c3f22a8-1479-435a-b9e9-b0b73675fd9b', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='33b01b39-935e-4d96-a1a6-115be5c48867', node_type=<ObjectType.DOCUMENT: '4'>, metadata={}, hash='12955538f5013c02589a8e9b0de261ca1b18cfec1cd7477f60456dfbcaf1ef99')}, text='RAG systems combine retrieval and generation for better results', mimetype='text/plain', start_char_idx=0, end_char_idx=63, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.6810204120173645)]\n",
            "Generated Response: RAG systems, or Retrieval-Augmented Generation systems, combine retrieval and generation to provide better results. These systems first retrieve relevant information from a large corpus of documents, and then use that information to generate a response. This approach allows the system to provide more accurate and contextually relevant answers, as it can draw on a wider range of information than would be possible with a traditional generative model.\n",
            "Source Documents:\n",
            "- This is a test document about RAG systems...\n",
            "- RAG systems combine retrieval and generation for better results...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"5d154c66-2237-4027-bf99-8c26a11e4dc9\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"5d154c66-2237-4027-bf99-8c26a11e4dc9\")) {                    Plotly.newPlot(                        \"5d154c66-2237-4027-bf99-8c26a11e4dc9\",                        [{\"y\":[0.8703420561313896,0.6810204120173645],\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"candlestick\":[{\"decreasing\":{\"line\":{\"color\":\"#000033\"}},\"increasing\":{\"line\":{\"color\":\"#000032\"}},\"type\":\"candlestick\"}],\"contourcarpet\":[{\"colorscale\":[[0.0,\"#000011\"],[0.1111111111111111,\"#000012\"],[0.2222222222222222,\"#000013\"],[0.3333333333333333,\"#000014\"],[0.4444444444444444,\"#000015\"],[0.5555555555555556,\"#000016\"],[0.6666666666666666,\"#000017\"],[0.7777777777777778,\"#000018\"],[0.8888888888888888,\"#000019\"],[1.0,\"#000020\"]],\"type\":\"contourcarpet\"}],\"contour\":[{\"colorscale\":[[0.0,\"#000011\"],[0.1111111111111111,\"#000012\"],[0.2222222222222222,\"#000013\"],[0.3333333333333333,\"#000014\"],[0.4444444444444444,\"#000015\"],[0.5555555555555556,\"#000016\"],[0.6666666666666666,\"#000017\"],[0.7777777777777778,\"#000018\"],[0.8888888888888888,\"#000019\"],[1.0,\"#000020\"]],\"type\":\"contour\"}],\"heatmap\":[{\"colorscale\":[[0.0,\"#000011\"],[0.1111111111111111,\"#000012\"],[0.2222222222222222,\"#000013\"],[0.3333333333333333,\"#000014\"],[0.4444444444444444,\"#000015\"],[0.5555555555555556,\"#000016\"],[0.6666666666666666,\"#000017\"],[0.7777777777777778,\"#000018\"],[0.8888888888888888,\"#000019\"],[1.0,\"#000020\"]],\"type\":\"heatmap\"}],\"histogram2d\":[{\"colorscale\":[[0.0,\"#000011\"],[0.1111111111111111,\"#000012\"],[0.2222222222222222,\"#000013\"],[0.3333333333333333,\"#000014\"],[0.4444444444444444,\"#000015\"],[0.5555555555555556,\"#000016\"],[0.6666666666666666,\"#000017\"],[0.7777777777777778,\"#000018\"],[0.8888888888888888,\"#000019\"],[1.0,\"#000020\"]],\"type\":\"histogram2d\"}],\"icicle\":[{\"textfont\":{\"color\":\"white\"},\"type\":\"icicle\"}],\"sankey\":[{\"textfont\":{\"color\":\"#000036\"},\"type\":\"sankey\"}],\"scatter\":[{\"marker\":{\"line\":{\"width\":0}},\"type\":\"scatter\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#000038\"},\"font\":{\"color\":\"#000037\"},\"line\":{\"color\":\"#000039\"}},\"header\":{\"fill\":{\"color\":\"#000040\"},\"font\":{\"color\":\"#000036\"},\"line\":{\"color\":\"#000039\"}},\"type\":\"table\"}],\"waterfall\":[{\"connector\":{\"line\":{\"color\":\"#000036\",\"width\":2}},\"decreasing\":{\"marker\":{\"color\":\"#000033\"}},\"increasing\":{\"marker\":{\"color\":\"#000032\"}},\"totals\":{\"marker\":{\"color\":\"#000034\"}},\"type\":\"waterfall\"}]},\"layout\":{\"coloraxis\":{\"colorscale\":[[0.0,\"#000011\"],[0.1111111111111111,\"#000012\"],[0.2222222222222222,\"#000013\"],[0.3333333333333333,\"#000014\"],[0.4444444444444444,\"#000015\"],[0.5555555555555556,\"#000016\"],[0.6666666666666666,\"#000017\"],[0.7777777777777778,\"#000018\"],[0.8888888888888888,\"#000019\"],[1.0,\"#000020\"]]},\"colorscale\":{\"diverging\":[[0.0,\"#000021\"],[0.1,\"#000022\"],[0.2,\"#000023\"],[0.3,\"#000024\"],[0.4,\"#000025\"],[0.5,\"#000026\"],[0.6,\"#000027\"],[0.7,\"#000028\"],[0.8,\"#000029\"],[0.9,\"#000030\"],[1.0,\"#000031\"]],\"sequential\":[[0.0,\"#000011\"],[0.1111111111111111,\"#000012\"],[0.2222222222222222,\"#000013\"],[0.3333333333333333,\"#000014\"],[0.4444444444444444,\"#000015\"],[0.5555555555555556,\"#000016\"],[0.6666666666666666,\"#000017\"],[0.7777777777777778,\"#000018\"],[0.8888888888888888,\"#000019\"],[1.0,\"#000020\"]],\"sequentialminus\":[[0.0,\"#000011\"],[0.1111111111111111,\"#000012\"],[0.2222222222222222,\"#000013\"],[0.3333333333333333,\"#000014\"],[0.4444444444444444,\"#000015\"],[0.5555555555555556,\"#000016\"],[0.6666666666666666,\"#000017\"],[0.7777777777777778,\"#000018\"],[0.8888888888888888,\"#000019\"],[1.0,\"#000020\"]]},\"colorway\":[\"#000001\",\"#000002\",\"#000003\",\"#000004\",\"#000005\",\"#000006\",\"#000007\",\"#000008\",\"#000009\",\"#000010\"]}},\"title\":{\"text\":\"Relevance Scores of Retrieved Documents\"},\"xaxis\":{\"title\":{\"text\":\"Document\"}},\"yaxis\":{\"title\":{\"text\":\"Relevance Score\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('5d154c66-2237-4027-bf99-8c26a11e4dc9');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}